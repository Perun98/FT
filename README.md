#Fine-tuning demo

** prepare_fine_tune_data.py
This Python code imports modules and functions, reads files from directories, processes them, and outputs the results in a JSON file.

The code begins by importing the necessary modules: os, json, and sys. The os module is used to access the operating system functionalities, while json is 
used to encode and decode JSON objects. The sys module is used to manipulate the Python runtime environment.

The code then inserts a path to a local Python module named my_functions, which contains custom functions that will be used later in the code.

Next, the script defines two directory paths, src_dir and prompt_dir, which contain the input files that will be processed. These directories are relative 
paths to the current working directory.

The if __name__ == '__main__': block is used to define the main function of the code. Inside this block, the script first uses the os module to list all files
 in the src_dir directory.

Then, the script creates an empty list named data. This list will store the processed prompt and completion data.

The script then loops through all the files in the src_dir directory. For each file, it reads the completion data using the open_file() function from the 
my_functions module, passing the file path as an argument. It then reads the corresponding prompt data from the prompt_dir directory using the same function.

The script then creates a dictionary named info, which contains the prompt and completion data as key-value pairs.

The info dictionary is then appended to the data list.

After processing all files, the script writes the contents of the data list to a new file named 'plots.jsonl' using the json.dump() function, which writes the
 dictionary objects as a single line of JSON text to the output file. Each JSON object is separated by a newline character '\n'.

In summary, this code reads prompt and completion data from a set of input files, processes the data, and stores the results in a JSON file for further 
analysis or use in machine learning tasks.
***********

** list-fune_tuning_models.py
This code imports several libraries/modules, namely "os", "openai", "datetime", and "sys". It also imports a custom module "my_functions" located in the 
directory "C:\Users\djordje\PythonGPT3Tutorial".

The code then reads the OpenAI API key from a file called "openaiapikey.txt" using the custom function "open_file" from the "my_functions" module. The API key
 is then set to the "openai.api_key" variable.

The "open_ai_api_key" variable is set to the value of the "openai.api_key" environment variable from the operating system.

The code then makes a request to the OpenAI API using the "openai.FineTune.list()" method and stores the response in the "response" variable.

The user is then prompted to input either 'd' or 'n' to choose whether they want to see a shortened list of valid fine-tuned models or a full list of all 
fine-tuned models. The user's input is stored in the "obim" variable.

If the user enters 'd', the code prints a list of valid fine-tuned models. It iterates through the "response" variable and prints the model number, creation 
date, model name, fine-tuned model name, and status of each valid fine-tuned model.

If the user enters 'n', the code prints a list of all fine-tuned models. It simply prints the "response" variable.

Finally, an empty line is printed to separate the output from the command prompt.

***********

** create_questions_csv.py

This code begins by importing the "openai", "csv", and "sys" modules, as well as a custom module called "my_functions". The OpenAI API key is read from a file
 called "openaiapikey.txt" using the custom function "open_file" from the "my_functions" module and set to the "openai.api_key" variable.

Next, a function named "generate_question" is defined. This function takes a text prompt as an input, generates a question based on the prompt using the 
OpenAI API, and returns the generated question. It uses the "openai.Completion.create()" method to generate the question using the "text-davinci-003" model 
with specific parameters such as the prompt, temperature, max_tokens, top_p, frequency_penalty, and presence_penalty.

Then, the code opens an input CSV file called "input.csv" and creates a new CSV file to store the questions generated by the "generate_question" function. It 
initializes a "file_counter" variable with a value of 1 to keep track of the file suffix for each question. The code then loops through each row of the input 
CSV file and generates a question for each cell in the row. It creates a separate text file for each question with a suffix based on the "file_counter" 
variable, writes the generated question to the text file, and increments the "file_counter" variable for the next iteration. The generated questions are 
printed to the console as well.

Finally, the code writes each CSV line in a separate tex

******************


** finetune_comments.py

This code is written in Python and consists of several sections that use various libraries and functions to finetune an OpenAI GPT-3 model. Let's take a 
closer look at each section:

Import necessary libraries: This section imports the libraries that will be used in the code, including openai, os, sys, and a custom module called 
my_functions. openai is the official OpenAI Python library, os is a module that provides a portable way of using operating system dependent functionality, sys
 is a module that provides access to some variables used or maintained by the interpreter and to functions that interact strongly with the interpreter, and 
my_functions is a custom module created to provide some helper functions for interacting with OpenAI.

Read OpenAI API key from file: This section reads the OpenAI API key from a file called openaiapikey.txt using a function from the my_functions module. The 
key is stored in the openai.api_key variable.

Get user input for model name: This section prompts the user to enter the name of the model to be finetuned.

Upload file and finetune model: This section uploads a file called plots.jsonl using a function from the my_functions module and then uses another function 
from the same module to finetune the selected model (ft_model) with the uploaded file. The davinci engine is used for finetuning.

List all finetuned models: This section calls a function from the my_functions module to list all the finetuned models.

Get user input for finetuned model ID: This section prompts the user to enter the ID of the finetuned model to retrieve events and details.

Get events for finetuned model: This section calls a function from the my_functions module to retrieve the events for the selected finetuned model (ft_id).

Get details for finetuned model: This section calls a function from the my_functions module to retrieve the details for the selected finetuned model (ft_id).

********************

** syntesize_plots.py

This code imports necessary modules such as openai, time, uuid, sys, and a custom module named my_functions. The openai module is used for communicating with 
OpenAI's GPT-3 API, while time, uuid, and sys are used for various utility purposes such as generating unique filenames and handling file paths. The custom 
module my_functions likely contains additional utility functions and is imported to make use of its functions.

After importing the necessary modules, the code defines several lists containing different values. The genres, modifiers, places, and periods lists contain 
strings representing different categories of data. For example, the genres list contains strings representing different types of painting work. These lists 
will be used later to generate prompts for the GPT-3 API.

Next, the code defines a function named gpt3_completion which handles communicating with the OpenAI API and returning a response. The function takes several 
parameters such as prompt, engine, temp, top_p, tokens, freq_pen, pres_pen, and stop, which are used to configure the behavior of the API request. The 
function attempts to make a request to the API and returns the response text if successful. If an error occurs, the function will retry up to 5 times before 
returning an error message.

Finally, the code enters the if __name__ == '__main__': block, which is the entry point of the script. The code iterates through every combination of 
categories in the genres, modifiers, places, and periods lists, generating a prompt using the contents of each category. The gpt3_completion function is then 
called with the generated prompt, and the resulting completion text is saved to a file using a unique filename based on the current time. The prompt and 
completion text are also printed to the console for debugging purposes. The loop will stop after 500 iterations, which is likely used for testing purposes.

******************